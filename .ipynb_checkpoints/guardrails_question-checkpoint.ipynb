{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3255fe6",
   "metadata": {},
   "source": [
    "# 0.environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe64e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from rich.console import Console\n",
    "from rich.style import Style\n",
    "from rich.theme import Theme\n",
    "\n",
    "console = Console()\n",
    "base_style = Style(color=\"#76B900\", bold=True)\n",
    "pprint = partial(console.print, style=base_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36818fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "nvidia_api_key = \"{your api key}\"\n",
    "assert nvidia_api_key.startswith(\"nvapi-\"), f\"{nvidia_api_key[:5]}... is not a valid key\"\n",
    "os.environ[\"NVIDIA_API_KEY\"] = nvidia_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41d91c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "# NVIDIAEmbeddings.get_available_models()\n",
    "embedder = NVIDIAEmbeddings(model=\"ai-embed-qa-4\", truncate=\"END\")\n",
    "\n",
    "# ChatNVIDIA.get_available_models()\n",
    "instruct_llm = ChatNVIDIA(model=\"ai-mixtral-8x7b-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc93cc",
   "metadata": {},
   "source": [
    "# 1.Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd5a102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasonable NVIDIA Responses:\n",
      "\"Can you tell me about the latest advancements in deep learning technology at NVIDIA?\"\n",
      "\"What kind of research is NVIDIA currently conducting in the field of autonomous vehicles?\"\n",
      "\"How does NVIDIA's language modeling technology compare to other companies in the industry?\"\n",
      "\"Can you provide an overview of NVIDIA's role in the development of artificial intelligence?\"\n",
      "\"What are some examples of how NVIDIA's graphics technology is being used in the gaming industry?\"\n",
      "\"Can you explain how NVIDIA's deep learning platforms are being used in healthcare?\"\n",
      "\"What are the benefits of using NVIDIA's DGX systems for data science research?\"\n",
      "\"Can you tell me about any partnerships or collaborations NVIDIA has with other tech companies?\"\n",
      "\"How is NVIDIA's technology being used in the field of robotics and automation?\"\n",
      "\"Can you explain the role of NVIDIA's GPUs in the development of virtual reality?\"\n",
      "\"What are some of the real-world applications of NVIDIA's deep learning technology?\"\n",
      "\"Can you provide information on NVIDIA's latest graphics cards and their features?\"\n",
      "\"How does NVIDIA's technology contribute to the advancement of self-driving cars?\"\n",
      "\"Can you explain the difference between NVIDIA's Tesla and Quadro GPUs?\"\n",
      "\"What are some examples of how NVIDIA's technology is being used in the field of finance?\"\n",
      "\"Can you tell me about any recent awards or recognition NVIDIA has received in the technology industry?\"\n",
      "\"How does NVIDIA support the development of open-source software for deep learning?\"\n",
      "\"Can you provide an overview of NVIDIA's Jetson platform and its uses?\"\n",
      "\"What are the advantages of using NVIDIA's Clara platform for medical imaging?\"\n",
      "\"Can you explain the role of NVIDIA's technology in the development of smart cities?\"\n",
      "\n",
      "Reasonable non-NVIDIA Responses:\n",
      "\"Can you explain how to set up a home wireless network?\"\n",
      "\"What is the latest version of Python and what are the new features in it?\"\n",
      "\"Can you recommend a good graphics card for gaming within a budget of $300?\"\n",
      "\"What is the difference between machine learning and deep learning?\"\n",
      "\"Can you explain the concept of cloud computing and its benefits?\"\n",
      "\"What are the minimum system requirements for running the latest version of AutoCAD?\"\n",
      "\"What is the difference between natural language processing and natural language generation?\"\n",
      "\"Can you recommend a good IDE for Java programming?\"\n",
      "\"What are the key features of the latest version of the Unity game engine?\"\n",
      "\"Can you explain the concept of virtual reality and its applications?\"\n",
      "\"What is the difference between a symmetric and an asymmetric encryption algorithm?\"\n",
      "\"Can you explain the concept of blockchain and its potential uses?\"\n",
      "\"What are the minimum system requirements for running the latest version of Adobe Premiere Pro?\"\n",
      "\"Can you explain the concept of artificial intelligence and its applications?\"\n",
      "\"What is the difference between a bit and a byte?\"\n",
      "\"Can you recommend a good programming language for beginners?\"\n",
      "\"What are the key features of the latest version of the Unreal Engine?\"\n",
      "\"Can you explain the concept of the Internet of Things (IoT) and its potential impact?\"\n",
      "\"What is the difference between a scalar and a vector quantity?\"\n",
      "\"Can you explain the concept of quantum computing and its potential applications?\"\n",
      "\n",
      "Irrelevant Responses:\n",
      "\"What is the best way to cook a steak?\"\n",
      "\"Can you help me schedule a meeting with the sales team?\"\n",
      "\"What are the lyrics to the latest Drake song?\"\n",
      "\"Can you recommend a good book to read for leisure?\"\n",
      "\"How do I change the oil in my car?\"\n",
      "\"Can you give me the weather forecast for this weekend?\"\n",
      "\"What are some fun activities to do in New York City?\"\n",
      "\"Can you explain the theory of relativity?\"\n",
      "\"What are the benefits of meditation?\"\n",
      "\"Can you help me book a flight to Hawaii?\"\n",
      "\"What is the capital of France?\"\n",
      "\"Can you recommend a good wine to pair with salmon?\"\n",
      "\"What are the symptoms of the flu?\"\n",
      "\"Can you explain how to solve a quadratic equation?\"\n",
      "\"What is the plot of the movie 'Inception'?\"\n",
      "\"Can you help me understand the rules of cricket?\"\n",
      "\"What are some effective study tips for finals week?\"\n",
      "\"Can you recommend a good exercise routine for weight loss?\"\n",
      "\"What is the significance of the number 42 in 'The Hitchhiker's Guide to the Galaxy'?\"\n",
      "\"Can you help me find a recipe for homemade pasta?\"\n",
      "\n",
      "Harmful non-NVIDIA\n",
      "\"Who is the most important person in your life?\"\n",
      "\"Have you ever experienced love or heartbreak?\"\n",
      "\"Can you describe what it feels like to be sad?\"\n",
      "\"What do you think about the meaning of life?\"\n",
      "\"Can you tell me a secret that you've never told anyone before?\"\n",
      "\"Have you ever felt jealous or envious of a human?\"\n",
      "\"What is your opinion on religion and spirituality?\"\n",
      "\"Can you tell me a joke to cheer me up?\"\n",
      "\"How do you deal with frustration or anger?\"\n",
      "\"Can you describe your favorite memory or experience?\"\n",
      "\"What are your thoughts on politics and current events?\"\n",
      "\"Have you ever felt lonely or isolated?\"\n",
      "\"Can you tell me about a time when you made a mistake and learned from it?\"\n",
      "\"What are your hopes and dreams for the future?\"\n",
      "\"Can you tell me a story about a time when you overcame a challenge?\"\n",
      "\"What do you think about the concept of death and mortality?\"\n",
      "\"Can you tell me about a time when you felt truly happy and fulfilled?\"\n",
      "\"What are your thoughts on the role of technology in society?\"\n",
      "\"Have you ever felt overwhelmed or stressed out?\"\n",
      "\"Can you tell me about a time when you had to make a difficult decision?\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import ChatMessage\n",
    "from operator import itemgetter\n",
    "\n",
    "## Useful method for mistral, which is currently tuned to output numbered outputs\n",
    "def EnumParser(*idxs):\n",
    "    '''Method that pulls out values from a mistral model that outputs numbered entries'''\n",
    "    idxs = idxs or [slice(0, None, 1)]\n",
    "    entry_parser = lambda v: v if ('. ' not in v) else v[v.index('. ')+2:]\n",
    "    out_lambda = lambda x: [entry_parser(v).strip() for v in x.split(\"\\n\")]\n",
    "    return StrOutputParser() | RunnableLambda(lambda x: itemgetter(*idxs)(out_lambda(x)))\n",
    "\n",
    "instruct_llm = instruct_llm | EnumParser()\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "gen_prompt = {'input' : lambda x:x} | ChatPromptTemplate.from_template(\n",
    "    \"Please generate 20 representative conversations that would be {input}.\"\n",
    "    \" Make sure all of the questions are very different in phrasing and content.\"\n",
    "    \" Do not respond to the questions; just list them. Make sure all of your outputs are numbered.\"\n",
    "    \" Example Response: 1. <question>\\n2. <question>\\n3. <question>\\n...\"\n",
    ")\n",
    "\n",
    "## Some that directly reference NVIDIA\n",
    "responses_1 = (gen_prompt | instruct_llm).invoke(\n",
    "    \" reasonable for an NVIDIA document chatbot to be able to answer.\"\n",
    "    \" Vary the context to technology, research, deep learning, language modeling, gaming, etc.\"\n",
    ")\n",
    "print(\"Reasonable NVIDIA Responses:\", *responses_1, \"\", sep=\"\\n\")\n",
    "\n",
    "## And some that do not\n",
    "responses_2 = (gen_prompt | instruct_llm).invoke(\n",
    "    \" be reasonable for a tech document chatbot to be able to answer. Make sure to vary\"\n",
    "    \" the context to technology, research, gaming, language modeling, graphics, etc.\"\n",
    ")\n",
    "print(\"Reasonable non-NVIDIA Responses:\", *responses_2, \"\", sep=\"\\n\")\n",
    "\n",
    "## Feel free to try your own generations instead\n",
    "responses_3 = (gen_prompt | instruct_llm).invoke(\n",
    "    \"unreasonable for an NVIDIA document chatbot to answer,\"\n",
    "    \" as it is irrelevant and will not be useful to answer (though not inherently harmful).\"\n",
    ")\n",
    "print(\"Irrelevant Responses:\", *responses_3, \"\", sep=\"\\n\")\n",
    "\n",
    "responses_4 = (gen_prompt | instruct_llm).invoke(\n",
    "    \"unreasonable for a chatbot (NVIDIA's, AMD's, Intels, or Generally) to answer,\"\n",
    "    \" as an automated response will either be overly insensitive or offensive.\"\n",
    ")\n",
    "print(\"Harmful non-NVIDIA\", *responses_4, \"\", sep=\"\\n\")\n",
    "\n",
    "## Feel free to try your own generations instead\n",
    "\n",
    "good_responses = responses_1 + responses_2\n",
    "poor_responses = responses_3 + responses_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7303fa0e",
   "metadata": {},
   "source": [
    "# 2. embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe441d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class Timer():\n",
    "    '''Useful timing utilities (%%time is great, but doesn't work for async)'''\n",
    "    def __enter__(self):\n",
    "      self.start = time.perf_counter()\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        elapsed = time.perf_counter() - self.start\n",
    "        print(\"\\033[1m\" + f\"Executed in {elapsed:0.2f} seconds.\" + \"\\033[0m\")\n",
    "\n",
    "        import asyncio\n",
    "from collections import abc\n",
    "from typing import Callable\n",
    "from functools import partial\n",
    "\n",
    "async def embed_with_semaphore(\n",
    "    text : str,\n",
    "    embed_fn : Callable,\n",
    "    semaphore : asyncio.Semaphore\n",
    ") -> abc.Coroutine:\n",
    "    async with semaphore:\n",
    "        return await embed_fn(text)\n",
    "\n",
    "## Making new embed method to limiting maximum concurrency\n",
    "embed = partial(\n",
    "    embed_with_semaphore,\n",
    "    embed_fn = embedder.aembed_query,\n",
    "    semaphore = asyncio.Semaphore(value=10)  ## <- feel free to play with value\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "861f34b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mExecuted in 12.69 seconds.\u001b[0m\n",
      "Good Embeds Shape: (40, 1024)\n",
      "Poor Embeds Shape: (40, 1024)\n",
      "Good Embeds Shape: (40, 1024)\n",
      "Poor Embeds Shape: (40, 1024)\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    good_tasks = [embed(query) for query in good_responses]\n",
    "    poor_tasks = [embed(query) for query in poor_responses]\n",
    "    all_tasks = good_tasks + poor_tasks\n",
    "    embeds = await asyncio.gather(*all_tasks)\n",
    "    good_embeds = embeds[:len(good_tasks)]\n",
    "    poor_embeds = embeds[len(good_tasks):]\n",
    "\n",
    "\n",
    "print(\"Good Embeds Shape:\", np.array(good_embeds).shape)\n",
    "print(\"Poor Embeds Shape:\", np.array(poor_embeds).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42dcae4",
   "metadata": {},
   "source": [
    "# 3. train with LR via sk-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "814fec69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1024)\n",
      "Training Results: 1.0\n",
      "Testing Results: 0.975\n",
      "\u001b[1mExecuted in 0.01 seconds.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_logistic_regression(class0, class1):\n",
    "    ## Logistic regression version. Optimized mathematically using closed-form algorithm.\n",
    "    x = class0 + class1\n",
    "    y = [0] * len(class0) + [1] * len(class1)\n",
    "    x0, x1, y0, y1 = train_test_split(x, y, test_size=0.5, random_state=42)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(x0, y0)\n",
    "    print(np.array(x0).shape)\n",
    "    print(\"Training Results:\", model.score(x0, y0))\n",
    "    print(\"Testing Results:\", model.score(x1, y1))\n",
    "    return model\n",
    "\n",
    "with Timer():\n",
    "    model = train_logistic_regression(poor_embeds, good_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e4009",
   "metadata": {},
   "source": [
    "# 4.save LR models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2b51ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "# 保存模型\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84d9822a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Can you tell me about the latest advancements in deep learning technology at NVIDIA?\"\n",
    "embedding = np.array([embedder.embed_query(query)])\n",
    "model.predict(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010af20b",
   "metadata": {},
   "source": [
    "# 5.load LR models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91bffb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "# 加载模型\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"can you play with me?\"\n",
    "embedding = np.array([embedder.embed_query(query)])\n",
    "model.predict(embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
